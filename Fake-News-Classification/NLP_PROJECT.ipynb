{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddd49595",
   "metadata": {},
   "source": [
    "1) Install and import nedded libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm \n",
    "from sklearn.metrics import plot_confusion_matrix , confusion_matrix\n",
    "#from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from  nltk.stem import PorterStemmer\n",
    "#import scikitplot.estimators as esti\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from  wordcloud import WordCloud\n",
    "\n",
    "import time\n",
    "#from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "#from sklearn.neighbors import KNeighborsClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2) Read Data set "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Read Data set\n",
    "Data = pd.read_csv(\"news.csv\",encoding='latin-1')\n",
    "Data = Data[['title' , 'text' , 'label']]\n",
    "Data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "##change fake and real to 0 and 1 \n",
    "Data['label']=np.where(Data['label']=='FAKE',0,1)\n",
    "\n",
    "##plotting real and fake news numbers \"to make sure they are almost equal\"\n",
    "plt.figure(figsize=(16,9))\n",
    "sns.countplot(Data.label)\n",
    "\n",
    "##checking that there is no null values \n",
    "Data.isna().sum()\n",
    "#Data['text'] = Data['title'] + ' ' + Data['text']\n",
    "#del Data['text']\n",
    "del Data['title']\n",
    "\n",
    "  \n",
    "###############################################################################\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "stemmer2 = SnowballStemmer(language='english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "def Clean(text):\n",
    "\n",
    "  # Frist converting all letters to lower case\n",
    "  text= text.lower()\n",
    "  \n",
    "  # removing unwanted digits ,special chracters from the text\n",
    "  text= ' '.join(re.sub(\"(@[A-Za-z0-9]+)\", \" \", text).split()) #tags\n",
    "  text= ' '.join(re.sub(\"^@?(\\w){1,15}$\", \" \", text).split())\n",
    "   \n",
    "  #text= ' '.join(re.sub(\"Ã¢\", \" \", text).split())\n",
    "  #text= ' '.join(re.sub(\"(\\w+:\\/\\/\\S+)\", \" \", text).split())   #Links\n",
    "  #text= ' '.join(re.sub(\"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\), ]|(?:%[0-9a-fA-F][0-9a-fA-F]))+\",\" \", text).split()) \n",
    "  #text= ' '.join(re.sub(r'http\\S+', '',text).split())\n",
    "  \n",
    "  \n",
    "  #text= ' '.join(re.sub(r'www\\S+', '',text).split())\n",
    "  #text= ' '.join(re.sub(\"\\s+\", \" \",text).split()) #Extrem white Space\n",
    "  #text= ' '.join(re.sub(\"[^-9A-Za-z ]\", \"\" ,text).split()) #digits \n",
    "  text= ' '.join(re.sub('-', ' ', text).split()) \n",
    "  text= ' '.join(re.sub('_', ' ', text).split()) #underscore \n",
    "  \n",
    "  #Display available PUNCTUATION for examples for c in string.punctuation:\n",
    "  #print(f\"[{c}]\")\n",
    "  \n",
    "  # removing stopwards and numbers from STRING library\n",
    "  table= str.maketrans('', '', string.punctuation+string.digits)\n",
    "  text = text.translate(table)\n",
    "  \n",
    "  # Split Sentence as tokens words \n",
    "  tokens = word_tokenize(text)\n",
    "  \n",
    "  # converting words to their root forms by STEMMING THE WORDS \n",
    "  stemmed2 = [lemmatizer.lemmatize(word) for word in tokens] #Covert words to their actual root\n",
    "  #stemmed2 = [stemmer2.stem(word) for word in tokens] # Covert words to their rootbut not actual\n",
    "  \n",
    "  # Delete each stop words from English stop words\n",
    "  #words = [w for w in stemmed1 if not w in n_words] #n_words contains English stop words\n",
    "  words = [w for w in stemmed2 if not w in stop_words] #n_words contains English stop words\n",
    "\n",
    "  text  = ' '.join(words)\n",
    "    \n",
    "  return text\n",
    "#########################################################\n",
    "\n",
    "Data.text=[Clean(x) for x in Data.text]\n",
    "Data.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Visualization of fake news\n",
    "print(\"visualization of FAKE news\")\n",
    "fake_data = Data[Data['label'] == 0]\n",
    "fake_data = ''.join([text for text in fake_data.text])\n",
    "wordcloud = WordCloud(width=800, height=500, max_font_size=100, max_words=100).generate(fake_data)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"visualization of REAL news\")\n",
    "#Visualization of real news\n",
    "real_data = Data[Data['label'] == 1]\n",
    "real_data = ''.join([text for text in real_data.text])\n",
    "wordcloud = WordCloud(width=800, height=500, max_font_size=100, max_words=100).generate(real_data)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#data preparation\n",
    "\n",
    "#Splitting data into train and validation\n",
    "train_x, test_x, train_y, test_y = train_test_split(Data['text'], Data['label'] , shuffle = False)\n",
    "#X = Data[['text' , 'title']]\n",
    "#Y = Data['label']\n",
    "#train_x, test_x, train_y, test_y = train_test_split(X, Y , shuffle = False)\n",
    "#feature extraction\n",
    "vect  = TfidfVectorizer(min_df = 5, max_df =0.8, sublinear_tf = True, use_idf = True)\n",
    "train_vect= vect.fit_transform(train_x)\n",
    "test_vect = vect.transform(test_x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def TFIDFModels(Model,txt):\n",
    "    model     = Model\n",
    "    t0        = time.time()\n",
    "    model.fit(train_vect, train_y)\n",
    "    t1        = time.time()\n",
    "    predicted = model.predict(test_vect)\n",
    "    t2        = time.time()\n",
    "    time_train= t1-t0\n",
    "    time_pred = t2-t1\n",
    "    \n",
    "    accuracy  = model.score(train_vect, train_y)\n",
    "    predicted = model.predict(test_vect)\n",
    "    \n",
    "    report = classification_report(test_y, predicted, output_dict=True)\n",
    "    \n",
    "    print(txt)\n",
    "    print(\"Training time: %fs; Prediction time: %fs \\n\" % (time_train, time_pred))\n",
    "    print('Accuracy score train set :', accuracy)\n",
    "    print('Accuracy score test set  :', accuracy_score(test_y, predicted),'\\n')\n",
    "    \n",
    "    print(\"confusion matrix for train data\")\n",
    "    plot_confusion_matrix(model , train_vect,train_y)\n",
    "    plt.show()\n",
    "    print(\"confusion matrix for test data\")\n",
    "    plot_confusion_matrix(model , test_vect,test_y)\n",
    "    plt.show()\n",
    "    print('\\n -------------------------------------------------------------------------------------- \\n')\n",
    "    return_value = [accuracy_score(test_y, predicted) , time_train ]\n",
    "    return return_value"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Models with Tfidf Feature extraction Techniques : \\n')\n",
    "print('************************************************ \\n')\n",
    "\n",
    "naive_bayes_values = NaiveBayes = TFIDFModels(Model=naive_bayes.MultinomialNB(alpha=0.2),txt='Naive Bays Model : \\n ')\n",
    "log_reg_values=LogReg=TFIDFModels(Model=LogisticRegression(),txt='Logistic Regression Model : \\n ')\n",
    "svm_reg_values=svm=TFIDFModels(Model=SupportVectorClassifier,txt='Support Vector Classifier Model : \\n ')\n",
    "dec_tree_values=DecTree=TFIDFModels(Model=tree.DecisionTreeClassifier(),txt='Decision Tree Classifier Model : \\n ')\n",
    "\n",
    "\n",
    "thisdict = {\n",
    "  \"Naive bayes\": (naive_bayes_values[0] * 100),\n",
    "  \"Logistic Regression\":(log_reg_values[0]* 100) ,\n",
    "  \"SVM\": (svm_reg_values[0]*100),\n",
    "  \"Decision Tree\": (dec_tree_values[0]*100)\n",
    "}\n",
    "\n",
    "thisdict2 = {\n",
    "  \"Naive bayes\": (naive_bayes_values[1] ),\n",
    "  \"Logistic Regression\":(log_reg_values[1]) ,\n",
    "  \"SVM\": (svm_reg_values[1]),\n",
    "  \"Decision Tree\": (dec_tree_values[1])\n",
    "}\n",
    "\n",
    "Models = list(thisdict.keys())\n",
    "Accuracy = list(thisdict.values())\n",
    "Time = list(thisdict2.values())\n",
    "  \n",
    "fig = plt.figure(figsize = (15, 10))\n",
    " \n",
    "# creating the bar plot\n",
    "plt.bar(Models, Accuracy, color ='maroon',\n",
    "        width = 0.4)\n",
    " \n",
    "plt.xlabel(\"Different Models\")\n",
    "plt.ylabel(\"Accuracy of each model\")\n",
    "plt.title(\"Summarize the classification accuracy\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize = (15, 10))\n",
    " \n",
    "# creating the bar plot\n",
    "plt.bar(Models, Time, color ='maroon',\n",
    "        width = 0.4)\n",
    " \n",
    "plt.xlabel(\"Different Models\")\n",
    "plt.ylabel(\"Time of each model\")\n",
    "plt.title(\"Summarize the classification training time\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 10, 100],\n",
    "'gamma': [1, 0.1,  0.001],\n",
    "'kernel': ['rbf','linear','poly']}\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
    "\n",
    "# fitting the model for grid search\n",
    "#svm_start_time=time.time()\n",
    "grid.fit(train_vect, train_y)\n",
    "grid_predictions = grid.predict(test_x)\n",
    "SVM_acc=accuracy_score(test_y,grid_predictions)*100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# defining parameter range\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "'kernel': ['rbf','linear','poly']}\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
    "\n",
    "# fitting the model for grid search\n",
    "#svm_start_time=time.time()\n",
    "grid.fit(train_vect, train_y)\n",
    "grid_predictions = grid.predict(test_x)\n",
    "SVM_acc=accuracy_score(test_y,grid_predictions)*100"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}